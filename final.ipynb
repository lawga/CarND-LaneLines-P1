{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "(540, 960, 3)\n",
      "Currently processing image: ./test_images/challenge_Moment.jpg\n",
      "(540, 960, 3)\n",
      "Currently processing image: ./test_images/solidWhiteCurve.jpg\n",
      "(540, 960, 3)\n",
      "Currently processing image: ./test_images/solidWhiteRight.jpg\n",
      "(540, 960, 3)\n",
      "Currently processing image: ./test_images/solidYellowCurve.jpg\n",
      "(540, 960, 3)\n",
      "Currently processing image: ./test_images/solidYellowCurve2.jpg\n",
      "(540, 960, 3)\n",
      "Currently processing image: ./test_images/solidYellowLeft.jpg\n",
      "(540, 960, 3)\n",
      "Currently processing image: ./test_images/whiteCarLaneSwitch.jpg\n"
=======
      "Currently processing image: ./test_images/solidYellowCurve.jpg\n",
      "Currently processing image: ./test_images/solidYellowCurve2.jpg\n",
      "Currently processing image: ./test_images/solidWhiteCurve.jpg\n",
      "Currently processing image: ./test_images/solidWhiteRight.jpg\n",
      "Currently processing image: ./test_images/solidYellowLeft.jpg\n",
      "Currently processing image: ./test_images/whiteCarLaneSwitch.jpg\n",
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:14<00:00, 13.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "CPU times: user 3 s, sys: 1.4 s, total: 4.4 s\n",
      "Wall time: 16.5 s\n"
>>>>>>> 6ddd6b3f34b6808ca5dbac8393ee391af2a562c9
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import array\n",
    "from os.path import join, basename\n",
    "import matplotlib.image as mpimg\n",
    "from lane_finding import lane_finding_pipeline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    verbose = True\n",
    "    #if verbose:\n",
    "       #plt.ion()\n",
    "       # figManager = plt.get_current_fig_manager()\n",
    "        #figManager.window.showMaximized()\n",
    "\n",
    "    input_image_list = os.listdir(\"test_images/\")\n",
    "    input_image_dir = \"./test_images/\"\n",
    "    input_image_list = [join(input_image_dir, name) for name in input_image_list]\n",
    "    image_out_dir = 'test_images_output'\n",
    "\n",
    "\n",
    "    for image in input_image_list:\n",
    "        # Read in the image\n",
    "        image_raw = mpimg.imread(image)\n",
<<<<<<< HEAD
    "        image_raw_resized = cv2.resize(image_raw, dsize=(960,540), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        imshape = image_raw_resized.shape\n",
    "        print (imshape)\n",
=======
    "        imshape = image_raw.shape\n",
>>>>>>> 6ddd6b3f34b6808ca5dbac8393ee391af2a562c9
    "        vertices = np.array([[(100,imshape[0]),(450, 320), (520,320), (925,imshape[0])]], dtype=np.int32)\n",
    "        img_out = lane_finding_pipeline(image_raw, vertices)\n",
    "        out_path = join(image_out_dir, basename(image))\n",
    "        mpimg.imsave(out_path, img_out)\n",
    "\n",
    "        print('Currently processing image: {}'.format(image))\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    def process_image(image):\n",
    "        # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "        # TODO: put your pipeline here,\n",
    "        # you should return the final output (image where lines are drawn on lanes)\n",
    "        \n",
    "        image = cv2.resize(image, dsize=(960,540), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        #vertices = np.array([[(180,imshape[0]-50),(480, 320), (530,320), (825,imshape[0]-50)]], dtype=np.int32)\n",
    "        vertices = np.array([[(100,imshape[0]),(450, 320), (520,320), (925,imshape[0])]], dtype=np.int32)\n",
    "        result = lane_finding_pipeline(image, vertices)\n",
    "\n",
    "        return result\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:10<00:00, 20.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "CPU times: user 5.29 s, sys: 750 ms, total: 6.04 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,2)\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video width=\"960\" height=\"540\" controls>\n",
       "      <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "    </video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
<<<<<<< HEAD
     "execution_count": 6,
=======
     "execution_count": 7,
>>>>>>> 6ddd6b3f34b6808ca5dbac8393ee391af2a562c9
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "    <video width=\"960\" height=\"540\" controls>\n",
    "      <source src=\"{0}\">\n",
    "    </video>\n",
    "    \"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "        # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "        # TODO: put your pipeline here,\n",
    "        # you should return the final output (image where lines are drawn on lanes)\n",
    "        \n",
    "        image = cv2.resize(image, dsize=(960,540), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        vertices = np.array([[(180,imshape[0]-50),(480, 320), (530,320), (825,imshape[0]-50)]], dtype=np.int32)\n",
    "        #vertices = np.array([[(100,imshape[0]),(450, 320), (520,320), (925,imshape[0])]], dtype=np.int32)\n",
    "        result = lane_finding_pipeline(image, vertices)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "        # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "        # TODO: put your pipeline here,\n",
    "        # you should return the final output (image where lines are drawn on lanes)\n",
    "        \n",
    "        image = cv2.resize(image, dsize=(960,540), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        vertices = np.array([[(180,imshape[0]-50),(370, 360), (600,360), (825,imshape[0]-50)]], dtype=np.int32)\n",
    "        result = lane_finding_pipeline(image, vertices)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/challenge.mp4\n",
      "[MoviePy] Writing video test_videos_output/challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "  3%|▎         | 7/251 [00:00<00:13, 17.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "283.625 358.625 456.75 405.625\n",
      "0 0 0 0\n",
      "291.909090909 358.454545455 452.909090909 407.090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 31/251 [00:01<00:09, 22.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "308.375 385.25 443.375 387.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 43/251 [00:02<00:09, 22.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "280.833333333 377.5 460.333333333 393.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 99/251 [00:05<00:10, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "293.777777778 359.222222222 469.0 421.222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 123/251 [00:07<00:10, 12.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678.333333333 786.666666667 426.666666667 489.333333333\n",
      "0 0 0 0\n",
      "705.0 778.333333333 444.0 485.666666667\n",
      "0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 127/251 [00:07<00:09, 12.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576.0 599.0 364.0 378.0\n",
      "0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████▏    | 129/251 [00:07<00:09, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634.0 660.666666667 405.333333333 422.0\n",
      "0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 139/251 [00:08<00:08, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "219.0 315.0 486.0 423.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 159/251 [00:10<00:07, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "294.785714286 354.5 432.571428571 395.714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:17<00:00, 14.85it/s]\n"
=======
      "100%|██████████| 251/251 [00:24<00:00, 10.07it/s]\n"
>>>>>>> 6ddd6b3f34b6808ca5dbac8393ee391af2a562c9
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/challenge.mp4 \n",
      "\n",
<<<<<<< HEAD
      "CPU times: user 9.74 s, sys: 900 ms, total: 10.6 s\n",
      "Wall time: 19.3 s\n"
=======
      "CPU times: user 6.15 s, sys: 375 ms, total: 6.52 s\n",
      "Wall time: 26.1 s\n"
>>>>>>> 6ddd6b3f34b6808ca5dbac8393ee391af2a562c9
     ]
    }
   ],
   "source": [
    "challenge_output = 'test_videos_output/challenge.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip3 = VideoFileClip('test_videos/challenge.mp4').subclip(4,6)\n",
    "clip3 = VideoFileClip('test_videos/challenge.mp4')\n",
    "challenge_clip = clip3.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 10,
>>>>>>> 6ddd6b3f34b6808ca5dbac8393ee391af2a562c9
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
<<<<<<< HEAD
     "execution_count": 5,
=======
     "execution_count": 10,
>>>>>>> 6ddd6b3f34b6808ca5dbac8393ee391af2a562c9
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mpimg.imread('./test_images/challenge_Moment.jpg')\n",
    "image_raw_resized = cv2.resize(image, dsize=(960,540), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "imshape = image_raw_resized.shape\n",
    "print (imshape)\n",
    "vertices = np.array([[(180,imshape[0]-50),(370, 360), (600,360), (825,imshape[0]-50)]], dtype=np.int32)\n",
    "img_out = lane_finding_pipeline(image_raw_resized, vertices)\n",
    "out_path = './test_images_output/challenge_Moment.jpg'\n",
    "mpimg.imsave(out_path, img_out)\n",
    "\n",
    "print('Currently processing image: {}'.format('challenge_Moment.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
>>>>>>> 6ddd6b3f34b6808ca5dbac8393ee391af2a562c9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
