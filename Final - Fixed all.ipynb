{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540, 960, 3)\n",
      "Currently processing image: ./test_images/solidYellowCurve.jpg\n",
      "(540, 960, 3)\n",
      "Currently processing image: ./test_images/solidYellowCurve2.jpg\n",
      "(540, 960, 3)\n",
      "Currently processing image: ./test_images/solidWhiteCurve.jpg\n",
      "(540, 960, 3)\n",
      "Currently processing image: ./test_images/solidWhiteRight.jpg\n",
      "(540, 960, 3)\n",
      "Currently processing image: ./test_images/solidYellowLeft.jpg\n",
      "(540, 960, 3)\n",
      "Currently processing image: ./test_images/challenge_Moment.jpg\n",
      "(540, 960, 3)\n",
      "Currently processing image: ./test_images/whiteCarLaneSwitch.jpg\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import array\n",
    "from os.path import join, basename\n",
    "import matplotlib.image as mpimg\n",
    "from lane_finding import lane_finding_pipeline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    verbose = True\n",
    "    #if verbose:\n",
    "       #plt.ion()\n",
    "       # figManager = plt.get_current_fig_manager()\n",
    "        #figManager.window.showMaximized()\n",
    "\n",
    "    input_image_list = os.listdir(\"test_images/\")\n",
    "    input_image_dir = \"./test_images/\"\n",
    "    input_image_list = [join(input_image_dir, name) for name in input_image_list]\n",
    "    image_out_dir = 'test_images_output'\n",
    "\n",
    "\n",
    "    for image in input_image_list:\n",
    "        # Read in the image\n",
    "        image_raw = mpimg.imread(image)\n",
    "        image_raw_resized = cv2.resize(image_raw, dsize=(960,540), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        imshape = image_raw_resized.shape\n",
    "        print (imshape)\n",
    "        imshape = image_raw.shape\n",
    "        vertices = np.array([[(100,imshape[0]),(450, 320), (520,320), (925,imshape[0])]], dtype=np.int32)\n",
    "        img_out = lane_finding_pipeline(image_raw, vertices)\n",
    "        out_path = join(image_out_dir, basename(image))\n",
    "        mpimg.imsave(out_path, img_out)\n",
    "\n",
    "        print('Currently processing image: {}'.format(image))\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    def process_image(image):\n",
    "        # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "        # TODO: put your pipeline here,\n",
    "        # you should return the final output (image where lines are drawn on lanes)\n",
    "        \n",
    "        image = cv2.resize(image, dsize=(960,540), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        #vertices = np.array([[(180,imshape[0]-50),(480, 320), (530,320), (825,imshape[0]-50)]], dtype=np.int32)\n",
    "        vertices = np.array([[(100,imshape[0]),(450, 320), (520,320), (925,imshape[0])]], dtype=np.int32)\n",
    "        result = lane_finding_pipeline(image, vertices)\n",
    "\n",
    "        return result\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:15<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "CPU times: user 3.78 s, sys: 239 ms, total: 4.02 s\n",
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,2)\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video width=\"960\" height=\"540\" controls>\n",
       "      <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "    </video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "    <video width=\"960\" height=\"540\" controls>\n",
    "      <source src=\"{0}\">\n",
    "    </video>\n",
    "    \"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "        # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "        # TODO: put your pipeline here,\n",
    "        # you should return the final output (image where lines are drawn on lanes)\n",
    "        \n",
    "        image = cv2.resize(image, dsize=(960,540), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        vertices = np.array([[(180,imshape[0]-50),(370, 360), (600,360), (825,imshape[0]-50)]], dtype=np.int32)\n",
    "        result = lane_finding_pipeline(image, vertices)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/challenge.mp4\n",
      "[MoviePy] Writing video test_videos_output/challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/251 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 2/251 [00:00<00:13, 18.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "312.666666667 373.111111111 440.666666667 398.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  2%|▏         | 4/251 [00:00<00:13, 18.58it/s]\u001b[A\n",
      "  3%|▎         | 7/251 [00:00<00:12, 19.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "283.4 352.8 459.6 411.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  4%|▍         | 10/251 [00:00<00:12, 19.77it/s]\u001b[A\n",
      "  5%|▌         | 13/251 [00:00<00:11, 20.24it/s]\u001b[A\n",
      "  6%|▋         | 16/251 [00:00<00:11, 20.82it/s]\u001b[A\n",
      "  8%|▊         | 19/251 [00:00<00:11, 21.07it/s]\u001b[A\n",
      "  9%|▉         | 22/251 [00:01<00:10, 21.42it/s]\u001b[A\n",
      " 10%|▉         | 25/251 [00:01<00:10, 21.48it/s]\u001b[A\n",
      " 11%|█         | 28/251 [00:01<00:10, 21.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n",
      "311.875 397.25 440.5 378.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 31/251 [00:01<00:10, 20.76it/s]\u001b[A\n",
      " 14%|█▎        | 34/251 [00:01<00:10, 21.03it/s]\u001b[A\n",
      " 15%|█▍        | 37/251 [00:01<00:10, 21.05it/s]\u001b[A\n",
      " 16%|█▌        | 40/251 [00:01<00:09, 21.16it/s]\u001b[A\n",
      " 17%|█▋        | 43/251 [00:02<00:13, 15.41it/s]\u001b[A\n",
      " 18%|█▊        | 45/251 [00:02<00:14, 14.33it/s]\u001b[A\n",
      " 19%|█▊        | 47/251 [00:02<00:15, 13.02it/s]\u001b[A\n",
      " 20%|█▉        | 49/251 [00:02<00:16, 12.22it/s]\u001b[A\n",
      " 20%|██        | 51/251 [00:02<00:16, 11.80it/s]\u001b[A\n",
      " 21%|██        | 53/251 [00:03<00:17, 11.48it/s]\u001b[A\n",
      " 22%|██▏       | 55/251 [00:03<00:17, 11.26it/s]\u001b[A\n",
      " 23%|██▎       | 57/251 [00:03<00:17, 11.05it/s]\u001b[A\n",
      " 24%|██▎       | 59/251 [00:03<00:17, 11.00it/s]\u001b[A\n",
      " 24%|██▍       | 61/251 [00:03<00:17, 10.85it/s]\u001b[A\n",
      " 25%|██▌       | 63/251 [00:04<00:17, 10.84it/s]\u001b[A\n",
      " 26%|██▌       | 65/251 [00:04<00:17, 10.74it/s]\u001b[A\n",
      " 27%|██▋       | 67/251 [00:04<00:17, 10.70it/s]\u001b[A\n",
      " 27%|██▋       | 69/251 [00:04<00:17, 10.64it/s]\n",
      " 28%|██▊       | 71/251 [00:04<00:17, 10.51it/s]\u001b[A\n",
      " 29%|██▉       | 73/251 [00:05<00:16, 10.61it/s]\u001b[A\n",
      " 30%|██▉       | 75/251 [00:05<00:19,  9.11it/s]\u001b[A\n",
      " 31%|███       | 77/251 [00:05<00:18,  9.30it/s]\u001b[A\n",
      " 31%|███▏      | 79/251 [00:05<00:17,  9.64it/s]\u001b[A\n",
      " 32%|███▏      | 80/251 [00:05<00:17,  9.50it/s]\u001b[A\n",
      " 32%|███▏      | 81/251 [00:05<00:18,  9.26it/s]\u001b[A\n",
      " 33%|███▎      | 83/251 [00:06<00:17,  9.49it/s]\u001b[A\n",
      " 34%|███▍      | 85/251 [00:06<00:17,  9.66it/s]\u001b[A\n",
      " 35%|███▍      | 87/251 [00:06<00:16,  9.66it/s]"
     ]
    }
   ],
   "source": [
    "challenge_output = 'test_videos_output/challenge.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip3 = VideoFileClip('test_videos/challenge.mp4').subclip(4,6)\n",
    "clip3 = VideoFileClip('test_videos/challenge.mp4')\n",
    "challenge_clip = clip3.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mpimg.imread('./test_images/challenge_Moment.jpg')\n",
    "image_raw_resized = cv2.resize(image, dsize=(960,540), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "imshape = image_raw_resized.shape\n",
    "print (imshape)\n",
    "vertices = np.array([[(180,imshape[0]-50),(370, 360), (600,360), (825,imshape[0]-50)]], dtype=np.int32)\n",
    "img_out = lane_finding_pipeline(image_raw_resized, vertices)\n",
    "out_path = './test_images_output/challenge_Moment.jpg'\n",
    "mpimg.imsave(out_path, img_out)\n",
    "\n",
    "print('Currently processing image: {}'.format('challenge_Moment.jpg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
